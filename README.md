# airlaner-passenaer-statisfaction
üìå Project Overview

This project focuses on predicting airline passenger satisfaction using machine learning techniques.
The main emphasis of the project is data analysis, feature engineering, model development, and explainability, rather than deployment.

The goal is to demonstrate a solid data science workflow that reflects how real-world machine learning projects are designed and evaluated in practice.

‚∏ª

üéØ Business Problem

Airlines collect detailed passenger feedback related to:
	‚Ä¢	service quality,
	‚Ä¢	digital experience,
	‚Ä¢	comfort,
	‚Ä¢	flight delays,
	‚Ä¢	and overall travel satisfaction.

Objective:
Build a classification model that predicts whether a passenger is satisfied and identify the key drivers behind passenger satisfaction.

‚∏ª

üìä Dataset
	‚Ä¢	Source: Airline Passenger Satisfaction Dataset
	‚Ä¢	Target Variable: satisfaction (binary)
	‚Ä¢	Feature Groups:
	‚Ä¢	Service ratings (WiFi, Online Boarding, Seat Comfort, etc.)
	‚Ä¢	Flight-related information (distance, delays)
	‚Ä¢	Passenger type and travel class

‚∏ª

üß† Project Scope & Workflow

1Ô∏è‚É£ Exploratory Data Analysis (EDA)
	‚Ä¢	Categorical & numerical variable analysis
	‚Ä¢	Missing value detection
	‚Ä¢	Target distribution analysis
	‚Ä¢	Statistical summaries

2Ô∏è‚É£ Feature Engineering
	‚Ä¢	Composite service quality scores
	‚Ä¢	Delay-based indicators
	‚Ä¢	Binary flags and ratio features
	‚Ä¢	Outlier handling for numerical variables

3Ô∏è‚É£ Base Models
	‚Ä¢	Baseline model evaluation
	‚Ä¢	Performance comparison using ROC-AUC and F1-score

4Ô∏è‚É£ XGBoost Model & Hyperparameter Tuning
	‚Ä¢	Model: XGBoost Classifier
	‚Ä¢	Hyperparameter optimization using:
	‚Ä¢	GridSearchCV
	‚Ä¢	StratifiedKFold
	‚Ä¢	Optimization metric: ROC-AUC

5Ô∏è‚É£ Overfitting Control
	‚Ä¢	Comparison of training vs test performance
	‚Ä¢	Cross-validation metrics on training data

6Ô∏è‚É£ Model Explainability (SHAP)
	‚Ä¢	Global feature importance analysis
	‚Ä¢	SHAP summary and bar plots
	‚Ä¢	Dependence plots for key features
	‚Ä¢	Local explanations using waterfall plots

7Ô∏è‚É£ Pipeline Creation
	‚Ä¢	End-to-end machine learning pipeline including:
	‚Ä¢	Missing value imputation
	‚Ä¢	Feature scaling
	‚Ä¢	Trained XGBoost model

8Ô∏è‚É£ Model Persistence
	‚Ä¢	Final pipeline saved using joblib
	‚Ä¢	Model is reusable and ready for integration into an application environment

‚∏ª

üìà Model Performance (Final)
	‚Ä¢	ROC-AUC: ~0.99
	‚Ä¢	Accuracy: ~94%
	‚Ä¢	F1-score: ~0.94

The model demonstrates strong generalization with controlled overfitting.
